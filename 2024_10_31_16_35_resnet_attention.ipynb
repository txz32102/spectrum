{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.ResNet_attention import ResidualAttentionModel_92_32input_update\n",
    "import torch\n",
    "from util.util import load_data_percentage, SpecDataset, create_data_loaders\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size is 10, dim is 2, length is 32768\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "current_time = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "X, Y, Z = load_data_percentage('./data/X.npy', './data/Y.npy', './data/Z.npy', percentage=100) \n",
    "config = {\n",
    "    'model_type': 'resnet_attention',\n",
    "    'current_time': current_time,\n",
    "    'epoch': 250,\n",
    "    'batch_size': 32,\n",
    "    'cuda_device': torch.device(\"cuda:5\")\n",
    "}\n",
    "\n",
    "dataset = SpecDataset(X, Y, Z, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Train Loss: 8907.9531, Val Loss: 2507.2625, Test Loss: 17007.9609\n",
      "Saved best model with validation loss: 2507.2625\n",
      "Epoch [2/250], Train Loss: 8892.9404, Val Loss: 2504.6936, Test Loss: 17001.3516\n",
      "Saved best model with validation loss: 2504.6936\n",
      "Epoch [3/250], Train Loss: 8878.9688, Val Loss: 2502.4429, Test Loss: 16996.3945\n",
      "Saved best model with validation loss: 2502.4429\n",
      "Epoch [4/250], Train Loss: 8865.7236, Val Loss: 2500.8550, Test Loss: 16993.6953\n",
      "Saved best model with validation loss: 2500.8550\n",
      "Epoch [5/250], Train Loss: 8849.0859, Val Loss: 2500.0754, Test Loss: 16993.7227\n",
      "Saved best model with validation loss: 2500.0754\n",
      "Epoch [6/250], Train Loss: 8829.0957, Val Loss: 2500.1338, Test Loss: 16996.5645\n",
      "Epoch [7/250], Train Loss: 8809.8945, Val Loss: 2500.8984, Test Loss: 17001.8301\n",
      "Epoch [8/250], Train Loss: 8788.7256, Val Loss: 2502.3777, Test Loss: 17009.6465\n",
      "Epoch [9/250], Train Loss: 8767.0381, Val Loss: 2504.6909, Test Loss: 17020.1055\n",
      "Epoch [10/250], Train Loss: 8742.5840, Val Loss: 2507.6760, Test Loss: 17032.5039\n",
      "Epoch [11/250], Train Loss: 8719.4141, Val Loss: 2511.3093, Test Loss: 17046.7070\n",
      "Epoch [12/250], Train Loss: 8695.1465, Val Loss: 2515.7715, Test Loss: 17063.6016\n",
      "Epoch [13/250], Train Loss: 8671.2871, Val Loss: 2521.1458, Test Loss: 17083.3594\n",
      "Epoch [14/250], Train Loss: 8648.2285, Val Loss: 2527.0701, Test Loss: 17104.9648\n",
      "Epoch [15/250], Train Loss: 8624.7539, Val Loss: 2533.2502, Test Loss: 17127.4668\n",
      "Epoch [16/250], Train Loss: 8601.9121, Val Loss: 2539.4033, Test Loss: 17150.3145\n",
      "Epoch [17/250], Train Loss: 8579.9727, Val Loss: 2545.1672, Test Loss: 17172.7363\n",
      "Epoch [18/250], Train Loss: 8558.4473, Val Loss: 2550.4214, Test Loss: 17194.6094\n",
      "Epoch [19/250], Train Loss: 8537.8115, Val Loss: 2555.1377, Test Loss: 17215.3496\n",
      "Epoch [20/250], Train Loss: 8517.5479, Val Loss: 2558.8394, Test Loss: 17233.5117\n",
      "Epoch [21/250], Train Loss: 8497.8945, Val Loss: 2561.1445, Test Loss: 17248.3672\n",
      "Epoch [22/250], Train Loss: 8478.8252, Val Loss: 2562.0857, Test Loss: 17259.2695\n",
      "Epoch [23/250], Train Loss: 8460.3945, Val Loss: 2561.5574, Test Loss: 17265.7227\n",
      "Epoch [24/250], Train Loss: 8442.2852, Val Loss: 2559.5552, Test Loss: 17268.1172\n",
      "Epoch [25/250], Train Loss: 8424.7227, Val Loss: 2556.4143, Test Loss: 17266.5781\n",
      "Epoch [26/250], Train Loss: 8407.6738, Val Loss: 2552.5417, Test Loss: 17261.4062\n",
      "Epoch [27/250], Train Loss: 8391.0488, Val Loss: 2547.9155, Test Loss: 17252.8594\n",
      "Epoch [28/250], Train Loss: 8374.7256, Val Loss: 2542.8186, Test Loss: 17241.8066\n",
      "Epoch [29/250], Train Loss: 8358.8232, Val Loss: 2537.1423, Test Loss: 17228.6094\n",
      "Epoch [30/250], Train Loss: 8343.2451, Val Loss: 2531.2112, Test Loss: 17214.2617\n",
      "Epoch [31/250], Train Loss: 8327.8418, Val Loss: 2525.3679, Test Loss: 17198.3496\n",
      "Epoch [32/250], Train Loss: 8312.5605, Val Loss: 2519.8223, Test Loss: 17182.1914\n",
      "Epoch [33/250], Train Loss: 8297.3848, Val Loss: 2514.5098, Test Loss: 17164.4512\n",
      "Epoch [34/250], Train Loss: 8282.4736, Val Loss: 2509.3582, Test Loss: 17146.0742\n",
      "Epoch [35/250], Train Loss: 8267.7402, Val Loss: 2504.7510, Test Loss: 17127.9746\n",
      "Epoch [36/250], Train Loss: 8253.1084, Val Loss: 2500.3267, Test Loss: 17109.5586\n",
      "Epoch [37/250], Train Loss: 8238.7305, Val Loss: 2496.3831, Test Loss: 17090.4492\n",
      "Saved best model with validation loss: 2496.3831\n",
      "Epoch [38/250], Train Loss: 8224.5312, Val Loss: 2492.6709, Test Loss: 17070.6191\n",
      "Saved best model with validation loss: 2492.6709\n",
      "Epoch [39/250], Train Loss: 8210.6387, Val Loss: 2489.1072, Test Loss: 17051.2754\n",
      "Saved best model with validation loss: 2489.1072\n",
      "Epoch [40/250], Train Loss: 8197.1162, Val Loss: 2485.6624, Test Loss: 17032.9922\n",
      "Saved best model with validation loss: 2485.6624\n",
      "Epoch [41/250], Train Loss: 8184.0483, Val Loss: 2482.6047, Test Loss: 17017.1953\n",
      "Saved best model with validation loss: 2482.6047\n",
      "Epoch [42/250], Train Loss: 8171.5317, Val Loss: 2479.7146, Test Loss: 17003.6797\n",
      "Saved best model with validation loss: 2479.7146\n",
      "Epoch [43/250], Train Loss: 8159.5459, Val Loss: 2477.0081, Test Loss: 16989.3691\n",
      "Saved best model with validation loss: 2477.0081\n",
      "Epoch [44/250], Train Loss: 8148.0796, Val Loss: 2474.7605, Test Loss: 16976.1855\n",
      "Saved best model with validation loss: 2474.7605\n",
      "Epoch [45/250], Train Loss: 8137.0942, Val Loss: 2472.7183, Test Loss: 16964.0000\n",
      "Saved best model with validation loss: 2472.7183\n",
      "Epoch [46/250], Train Loss: 8126.5239, Val Loss: 2470.7173, Test Loss: 16951.1836\n",
      "Saved best model with validation loss: 2470.7173\n",
      "Epoch [47/250], Train Loss: 8116.3457, Val Loss: 2468.8979, Test Loss: 16938.4863\n",
      "Saved best model with validation loss: 2468.8979\n",
      "Epoch [48/250], Train Loss: 8106.5317, Val Loss: 2467.1758, Test Loss: 16925.4355\n",
      "Saved best model with validation loss: 2467.1758\n",
      "Epoch [49/250], Train Loss: 8097.0571, Val Loss: 2465.4961, Test Loss: 16913.8164\n",
      "Saved best model with validation loss: 2465.4961\n",
      "Epoch [50/250], Train Loss: 8087.8955, Val Loss: 2463.8394, Test Loss: 16902.4727\n",
      "Saved best model with validation loss: 2463.8394\n",
      "Epoch [51/250], Train Loss: 8079.0552, Val Loss: 2462.2180, Test Loss: 16889.8223\n",
      "Saved best model with validation loss: 2462.2180\n",
      "Epoch [52/250], Train Loss: 8070.4907, Val Loss: 2460.7195, Test Loss: 16879.1113\n",
      "Saved best model with validation loss: 2460.7195\n",
      "Epoch [53/250], Train Loss: 8062.1694, Val Loss: 2459.2554, Test Loss: 16871.4102\n",
      "Saved best model with validation loss: 2459.2554\n",
      "Epoch [54/250], Train Loss: 8054.0728, Val Loss: 2457.8118, Test Loss: 16864.2109\n",
      "Saved best model with validation loss: 2457.8118\n",
      "Epoch [55/250], Train Loss: 8046.1655, Val Loss: 2456.4226, Test Loss: 16858.2344\n",
      "Saved best model with validation loss: 2456.4226\n",
      "Epoch [56/250], Train Loss: 8038.4180, Val Loss: 2455.0483, Test Loss: 16852.7227\n",
      "Saved best model with validation loss: 2455.0483\n",
      "Epoch [57/250], Train Loss: 8030.8145, Val Loss: 2453.6934, Test Loss: 16847.1758\n",
      "Saved best model with validation loss: 2453.6934\n",
      "Epoch [58/250], Train Loss: 8023.3462, Val Loss: 2452.3345, Test Loss: 16841.1816\n",
      "Saved best model with validation loss: 2452.3345\n",
      "Epoch [59/250], Train Loss: 8016.0015, Val Loss: 2450.9470, Test Loss: 16835.8555\n",
      "Saved best model with validation loss: 2450.9470\n",
      "Epoch [60/250], Train Loss: 8008.7661, Val Loss: 2449.6523, Test Loss: 16830.2812\n",
      "Saved best model with validation loss: 2449.6523\n",
      "Epoch [61/250], Train Loss: 8001.6196, Val Loss: 2448.3398, Test Loss: 16825.7344\n",
      "Saved best model with validation loss: 2448.3398\n",
      "Epoch [62/250], Train Loss: 7994.5527, Val Loss: 2447.0134, Test Loss: 16820.1523\n",
      "Saved best model with validation loss: 2447.0134\n",
      "Epoch [63/250], Train Loss: 7987.5488, Val Loss: 2445.7078, Test Loss: 16815.0156\n",
      "Saved best model with validation loss: 2445.7078\n",
      "Epoch [64/250], Train Loss: 7980.6045, Val Loss: 2444.0999, Test Loss: 16808.1719\n",
      "Saved best model with validation loss: 2444.0999\n",
      "Epoch [65/250], Train Loss: 7973.7114, Val Loss: 2442.5103, Test Loss: 16802.8516\n",
      "Saved best model with validation loss: 2442.5103\n",
      "Epoch [66/250], Train Loss: 7966.9004, Val Loss: 2441.0352, Test Loss: 16798.8672\n",
      "Saved best model with validation loss: 2441.0352\n",
      "Epoch [67/250], Train Loss: 7960.0898, Val Loss: 2439.6003, Test Loss: 16793.5859\n",
      "Saved best model with validation loss: 2439.6003\n",
      "Epoch [68/250], Train Loss: 7953.3643, Val Loss: 2438.1086, Test Loss: 16786.3672\n",
      "Saved best model with validation loss: 2438.1086\n",
      "Epoch [69/250], Train Loss: 7946.6670, Val Loss: 2436.6323, Test Loss: 16781.5820\n",
      "Saved best model with validation loss: 2436.6323\n",
      "Epoch [70/250], Train Loss: 7939.9868, Val Loss: 2435.1958, Test Loss: 16777.3359\n",
      "Saved best model with validation loss: 2435.1958\n",
      "Epoch [71/250], Train Loss: 7933.3657, Val Loss: 2433.8521, Test Loss: 16770.5020\n",
      "Saved best model with validation loss: 2433.8521\n",
      "Epoch [72/250], Train Loss: 7926.7778, Val Loss: 2432.5107, Test Loss: 16763.4238\n",
      "Saved best model with validation loss: 2432.5107\n",
      "Epoch [73/250], Train Loss: 7920.1743, Val Loss: 2431.1606, Test Loss: 16757.7461\n",
      "Saved best model with validation loss: 2431.1606\n",
      "Epoch [74/250], Train Loss: 7913.6943, Val Loss: 2429.6599, Test Loss: 16751.6562\n",
      "Saved best model with validation loss: 2429.6599\n",
      "Epoch [75/250], Train Loss: 7907.1260, Val Loss: 2428.3525, Test Loss: 16743.0020\n",
      "Saved best model with validation loss: 2428.3525\n",
      "Epoch [76/250], Train Loss: 7900.7114, Val Loss: 2427.0469, Test Loss: 16734.2969\n",
      "Saved best model with validation loss: 2427.0469\n",
      "Epoch [77/250], Train Loss: 7894.1865, Val Loss: 2425.8171, Test Loss: 16727.5137\n",
      "Saved best model with validation loss: 2425.8171\n",
      "Epoch [78/250], Train Loss: 7887.8818, Val Loss: 2424.5090, Test Loss: 16723.7871\n",
      "Saved best model with validation loss: 2424.5090\n",
      "Epoch [79/250], Train Loss: 7881.3286, Val Loss: 2423.2192, Test Loss: 16713.7441\n",
      "Saved best model with validation loss: 2423.2192\n",
      "Epoch [80/250], Train Loss: 7875.0693, Val Loss: 2421.9331, Test Loss: 16705.8926\n",
      "Saved best model with validation loss: 2421.9331\n",
      "Epoch [81/250], Train Loss: 7868.5532, Val Loss: 2420.6890, Test Loss: 16696.3496\n",
      "Saved best model with validation loss: 2420.6890\n",
      "Epoch [82/250], Train Loss: 7862.3584, Val Loss: 2419.4351, Test Loss: 16688.4082\n",
      "Saved best model with validation loss: 2419.4351\n",
      "Epoch [83/250], Train Loss: 7855.8071, Val Loss: 2418.0601, Test Loss: 16681.4688\n",
      "Saved best model with validation loss: 2418.0601\n",
      "Epoch [84/250], Train Loss: 7849.6392, Val Loss: 2416.7209, Test Loss: 16668.7871\n",
      "Saved best model with validation loss: 2416.7209\n",
      "Epoch [85/250], Train Loss: 7843.2256, Val Loss: 2415.3984, Test Loss: 16661.2520\n",
      "Saved best model with validation loss: 2415.3984\n",
      "Epoch [86/250], Train Loss: 7836.8965, Val Loss: 2413.9480, Test Loss: 16651.2148\n",
      "Saved best model with validation loss: 2413.9480\n",
      "Epoch [87/250], Train Loss: 7830.6553, Val Loss: 2412.4268, Test Loss: 16639.3418\n",
      "Saved best model with validation loss: 2412.4268\n",
      "Epoch [88/250], Train Loss: 7824.3364, Val Loss: 2410.8628, Test Loss: 16629.1660\n",
      "Saved best model with validation loss: 2410.8628\n",
      "Epoch [89/250], Train Loss: 7818.1865, Val Loss: 2409.5352, Test Loss: 16620.0508\n",
      "Saved best model with validation loss: 2409.5352\n",
      "Epoch [90/250], Train Loss: 7811.8516, Val Loss: 2408.2336, Test Loss: 16615.0430\n",
      "Saved best model with validation loss: 2408.2336\n",
      "Epoch [91/250], Train Loss: 7805.5752, Val Loss: 2407.0339, Test Loss: 16603.9727\n",
      "Saved best model with validation loss: 2407.0339\n",
      "Epoch [92/250], Train Loss: 7799.4116, Val Loss: 2405.5679, Test Loss: 16584.8906\n",
      "Saved best model with validation loss: 2405.5679\n",
      "Epoch [93/250], Train Loss: 7793.1113, Val Loss: 2404.2720, Test Loss: 16573.3320\n",
      "Saved best model with validation loss: 2404.2720\n",
      "Epoch [94/250], Train Loss: 7787.0161, Val Loss: 2403.0144, Test Loss: 16566.4648\n",
      "Saved best model with validation loss: 2403.0144\n",
      "Epoch [95/250], Train Loss: 7780.6997, Val Loss: 2401.9688, Test Loss: 16560.9785\n",
      "Saved best model with validation loss: 2401.9688\n",
      "Epoch [96/250], Train Loss: 7774.6602, Val Loss: 2400.8770, Test Loss: 16547.3438\n",
      "Saved best model with validation loss: 2400.8770\n",
      "Epoch [97/250], Train Loss: 7768.3330, Val Loss: 2399.7471, Test Loss: 16534.3984\n",
      "Saved best model with validation loss: 2399.7471\n",
      "Epoch [98/250], Train Loss: 7762.3296, Val Loss: 2398.7637, Test Loss: 16526.1133\n",
      "Saved best model with validation loss: 2398.7637\n",
      "Epoch [99/250], Train Loss: 7756.0107, Val Loss: 2397.9102, Test Loss: 16519.4863\n",
      "Saved best model with validation loss: 2397.9102\n",
      "Epoch [100/250], Train Loss: 7749.9937, Val Loss: 2396.8440, Test Loss: 16505.4844\n",
      "Saved best model with validation loss: 2396.8440\n",
      "Epoch [101/250], Train Loss: 7743.7354, Val Loss: 2395.7502, Test Loss: 16493.8672\n",
      "Saved best model with validation loss: 2395.7502\n",
      "Epoch [102/250], Train Loss: 7737.5952, Val Loss: 2394.7568, Test Loss: 16486.4609\n",
      "Saved best model with validation loss: 2394.7568\n",
      "Epoch [103/250], Train Loss: 7731.4912, Val Loss: 2393.7263, Test Loss: 16484.2461\n",
      "Saved best model with validation loss: 2393.7263\n",
      "Epoch [104/250], Train Loss: 7725.3643, Val Loss: 2392.5120, Test Loss: 16472.4805\n",
      "Saved best model with validation loss: 2392.5120\n",
      "Epoch [105/250], Train Loss: 7719.1523, Val Loss: 2391.3542, Test Loss: 16464.2500\n",
      "Saved best model with validation loss: 2391.3542\n",
      "Epoch [106/250], Train Loss: 7713.0146, Val Loss: 2390.0544, Test Loss: 16459.7070\n",
      "Saved best model with validation loss: 2390.0544\n",
      "Epoch [107/250], Train Loss: 7706.8477, Val Loss: 2388.8801, Test Loss: 16460.1484\n",
      "Saved best model with validation loss: 2388.8801\n",
      "Epoch [108/250], Train Loss: 7700.7402, Val Loss: 2387.7996, Test Loss: 16458.9922\n",
      "Saved best model with validation loss: 2387.7996\n",
      "Epoch [109/250], Train Loss: 7694.6289, Val Loss: 2386.7278, Test Loss: 16442.6562\n",
      "Saved best model with validation loss: 2386.7278\n",
      "Epoch [110/250], Train Loss: 7688.5327, Val Loss: 2385.5576, Test Loss: 16439.5996\n",
      "Saved best model with validation loss: 2385.5576\n",
      "Epoch [111/250], Train Loss: 7682.3833, Val Loss: 2384.4736, Test Loss: 16437.7480\n",
      "Saved best model with validation loss: 2384.4736\n",
      "Epoch [112/250], Train Loss: 7676.2568, Val Loss: 2383.4187, Test Loss: 16431.6055\n",
      "Saved best model with validation loss: 2383.4187\n",
      "Epoch [113/250], Train Loss: 7670.1880, Val Loss: 2382.2815, Test Loss: 16420.4102\n",
      "Saved best model with validation loss: 2382.2815\n",
      "Epoch [114/250], Train Loss: 7664.0415, Val Loss: 2381.1409, Test Loss: 16417.1777\n",
      "Saved best model with validation loss: 2381.1409\n",
      "Epoch [115/250], Train Loss: 7657.9858, Val Loss: 2379.7952, Test Loss: 16416.1152\n",
      "Saved best model with validation loss: 2379.7952\n",
      "Epoch [116/250], Train Loss: 7651.8188, Val Loss: 2378.7512, Test Loss: 16405.5352\n",
      "Saved best model with validation loss: 2378.7512\n",
      "Epoch [117/250], Train Loss: 7645.7803, Val Loss: 2377.7151, Test Loss: 16392.0430\n",
      "Saved best model with validation loss: 2377.7151\n",
      "Epoch [118/250], Train Loss: 7639.6279, Val Loss: 2376.4587, Test Loss: 16392.0566\n",
      "Saved best model with validation loss: 2376.4587\n",
      "Epoch [119/250], Train Loss: 7633.5103, Val Loss: 2375.0332, Test Loss: 16393.4648\n",
      "Saved best model with validation loss: 2375.0332\n",
      "Epoch [120/250], Train Loss: 7627.4204, Val Loss: 2373.7466, Test Loss: 16388.7949\n",
      "Saved best model with validation loss: 2373.7466\n",
      "Epoch [121/250], Train Loss: 7621.2344, Val Loss: 2372.7185, Test Loss: 16371.8555\n",
      "Saved best model with validation loss: 2372.7185\n",
      "Epoch [122/250], Train Loss: 7615.1455, Val Loss: 2371.6135, Test Loss: 16358.8281\n",
      "Saved best model with validation loss: 2371.6135\n",
      "Epoch [123/250], Train Loss: 7609.0181, Val Loss: 2370.2197, Test Loss: 16358.4473\n",
      "Saved best model with validation loss: 2370.2197\n",
      "Epoch [124/250], Train Loss: 7602.9302, Val Loss: 2368.7651, Test Loss: 16355.6582\n",
      "Saved best model with validation loss: 2368.7651\n",
      "Epoch [125/250], Train Loss: 7596.8271, Val Loss: 2367.3821, Test Loss: 16351.4707\n",
      "Saved best model with validation loss: 2367.3821\n",
      "Epoch [126/250], Train Loss: 7590.7349, Val Loss: 2366.3091, Test Loss: 16336.4316\n",
      "Saved best model with validation loss: 2366.3091\n",
      "Epoch [127/250], Train Loss: 7584.6821, Val Loss: 2365.3279, Test Loss: 16329.7363\n",
      "Saved best model with validation loss: 2365.3279\n",
      "Epoch [128/250], Train Loss: 7578.5957, Val Loss: 2364.2266, Test Loss: 16326.3887\n",
      "Saved best model with validation loss: 2364.2266\n",
      "Epoch [129/250], Train Loss: 7572.5566, Val Loss: 2362.4514, Test Loss: 16335.5977\n",
      "Saved best model with validation loss: 2362.4514\n",
      "Epoch [130/250], Train Loss: 7566.4746, Val Loss: 2361.2905, Test Loss: 16322.7920\n",
      "Saved best model with validation loss: 2361.2905\n",
      "Epoch [131/250], Train Loss: 7560.3135, Val Loss: 2360.1821, Test Loss: 16309.2236\n",
      "Saved best model with validation loss: 2360.1821\n",
      "Epoch [132/250], Train Loss: 7554.2266, Val Loss: 2358.8521, Test Loss: 16313.0371\n",
      "Saved best model with validation loss: 2358.8521\n",
      "Epoch [133/250], Train Loss: 7548.1177, Val Loss: 2357.4604, Test Loss: 16314.3457\n",
      "Saved best model with validation loss: 2357.4604\n",
      "Epoch [134/250], Train Loss: 7542.0391, Val Loss: 2356.0408, Test Loss: 16302.3535\n",
      "Saved best model with validation loss: 2356.0408\n",
      "Epoch [135/250], Train Loss: 7535.8926, Val Loss: 2354.6150, Test Loss: 16289.9951\n",
      "Saved best model with validation loss: 2354.6150\n",
      "Epoch [136/250], Train Loss: 7529.8486, Val Loss: 2353.1843, Test Loss: 16286.1211\n",
      "Saved best model with validation loss: 2353.1843\n",
      "Epoch [137/250], Train Loss: 7523.7275, Val Loss: 2351.4011, Test Loss: 16294.3359\n",
      "Saved best model with validation loss: 2351.4011\n",
      "Epoch [138/250], Train Loss: 7517.5811, Val Loss: 2350.0269, Test Loss: 16288.9727\n",
      "Saved best model with validation loss: 2350.0269\n",
      "Epoch [139/250], Train Loss: 7511.5757, Val Loss: 2349.1895, Test Loss: 16267.7012\n",
      "Saved best model with validation loss: 2349.1895\n",
      "Epoch [140/250], Train Loss: 7505.3477, Val Loss: 2347.9976, Test Loss: 16254.6406\n",
      "Saved best model with validation loss: 2347.9976\n",
      "Epoch [141/250], Train Loss: 7499.4199, Val Loss: 2346.1223, Test Loss: 16267.9824\n",
      "Saved best model with validation loss: 2346.1223\n",
      "Epoch [142/250], Train Loss: 7493.1333, Val Loss: 2344.7964, Test Loss: 16268.6807\n",
      "Saved best model with validation loss: 2344.7964\n",
      "Epoch [143/250], Train Loss: 7487.1978, Val Loss: 2343.8757, Test Loss: 16247.1816\n",
      "Saved best model with validation loss: 2343.8757\n",
      "Epoch [144/250], Train Loss: 7480.8994, Val Loss: 2342.7947, Test Loss: 16229.1816\n",
      "Saved best model with validation loss: 2342.7947\n",
      "Epoch [145/250], Train Loss: 7475.0186, Val Loss: 2340.8804, Test Loss: 16236.1738\n",
      "Saved best model with validation loss: 2340.8804\n",
      "Epoch [146/250], Train Loss: 7468.6992, Val Loss: 2339.1077, Test Loss: 16239.1250\n",
      "Saved best model with validation loss: 2339.1077\n",
      "Epoch [147/250], Train Loss: 7462.8066, Val Loss: 2337.8210, Test Loss: 16222.5791\n",
      "Saved best model with validation loss: 2337.8210\n",
      "Epoch [148/250], Train Loss: 7456.5596, Val Loss: 2336.7273, Test Loss: 16199.3721\n",
      "Saved best model with validation loss: 2336.7273\n",
      "Epoch [149/250], Train Loss: 7450.4868, Val Loss: 2334.9307, Test Loss: 16200.8750\n",
      "Saved best model with validation loss: 2334.9307\n",
      "Epoch [150/250], Train Loss: 7444.3652, Val Loss: 2332.6123, Test Loss: 16204.9746\n",
      "Saved best model with validation loss: 2332.6123\n",
      "Epoch [151/250], Train Loss: 7438.2524, Val Loss: 2331.1868, Test Loss: 16185.0820\n",
      "Saved best model with validation loss: 2331.1868\n",
      "Epoch [152/250], Train Loss: 7432.1841, Val Loss: 2329.9834, Test Loss: 16159.9043\n",
      "Saved best model with validation loss: 2329.9834\n",
      "Epoch [153/250], Train Loss: 7426.0576, Val Loss: 2328.5330, Test Loss: 16155.4111\n",
      "Saved best model with validation loss: 2328.5330\n",
      "Epoch [154/250], Train Loss: 7419.9478, Val Loss: 2326.4553, Test Loss: 16160.3057\n",
      "Saved best model with validation loss: 2326.4553\n",
      "Epoch [155/250], Train Loss: 7413.8618, Val Loss: 2325.2295, Test Loss: 16148.9531\n",
      "Saved best model with validation loss: 2325.2295\n",
      "Epoch [156/250], Train Loss: 7407.7793, Val Loss: 2324.1760, Test Loss: 16134.2676\n",
      "Saved best model with validation loss: 2324.1760\n",
      "Epoch [157/250], Train Loss: 7401.6924, Val Loss: 2323.0237, Test Loss: 16121.3438\n",
      "Saved best model with validation loss: 2323.0237\n",
      "Epoch [158/250], Train Loss: 7395.6538, Val Loss: 2320.6289, Test Loss: 16134.3203\n",
      "Saved best model with validation loss: 2320.6289\n",
      "Epoch [159/250], Train Loss: 7389.4609, Val Loss: 2319.3000, Test Loss: 16131.7324\n",
      "Saved best model with validation loss: 2319.3000\n",
      "Epoch [160/250], Train Loss: 7383.4595, Val Loss: 2318.6936, Test Loss: 16112.6543\n",
      "Saved best model with validation loss: 2318.6936\n",
      "Epoch [161/250], Train Loss: 7377.3481, Val Loss: 2317.1401, Test Loss: 16109.0410\n",
      "Saved best model with validation loss: 2317.1401\n",
      "Epoch [162/250], Train Loss: 7371.3574, Val Loss: 2315.5312, Test Loss: 16112.7617\n",
      "Saved best model with validation loss: 2315.5312\n",
      "Epoch [163/250], Train Loss: 7365.2070, Val Loss: 2314.0122, Test Loss: 16108.5293\n",
      "Saved best model with validation loss: 2314.0122\n",
      "Epoch [164/250], Train Loss: 7359.1650, Val Loss: 2312.7666, Test Loss: 16088.4199\n",
      "Saved best model with validation loss: 2312.7666\n",
      "Epoch [165/250], Train Loss: 7353.1064, Val Loss: 2311.4751, Test Loss: 16073.7666\n",
      "Saved best model with validation loss: 2311.4751\n",
      "Epoch [166/250], Train Loss: 7347.0205, Val Loss: 2309.4258, Test Loss: 16082.0723\n",
      "Saved best model with validation loss: 2309.4258\n",
      "Epoch [167/250], Train Loss: 7340.9185, Val Loss: 2307.6511, Test Loss: 16077.1035\n",
      "Saved best model with validation loss: 2307.6511\n",
      "Epoch [168/250], Train Loss: 7334.9067, Val Loss: 2306.9937, Test Loss: 16049.5254\n",
      "Saved best model with validation loss: 2306.9937\n",
      "Epoch [169/250], Train Loss: 7328.7896, Val Loss: 2305.4348, Test Loss: 16043.3906\n",
      "Saved best model with validation loss: 2305.4348\n",
      "Epoch [170/250], Train Loss: 7322.7861, Val Loss: 2303.5720, Test Loss: 16051.0859\n",
      "Saved best model with validation loss: 2303.5720\n",
      "Epoch [171/250], Train Loss: 7316.6567, Val Loss: 2302.1785, Test Loss: 16040.5234\n",
      "Saved best model with validation loss: 2302.1785\n",
      "Epoch [172/250], Train Loss: 7310.6465, Val Loss: 2301.0020, Test Loss: 16021.3467\n",
      "Saved best model with validation loss: 2301.0020\n",
      "Epoch [173/250], Train Loss: 7304.5596, Val Loss: 2300.0405, Test Loss: 16010.0137\n",
      "Saved best model with validation loss: 2300.0405\n",
      "Epoch [174/250], Train Loss: 7298.5298, Val Loss: 2297.5139, Test Loss: 16022.7441\n",
      "Saved best model with validation loss: 2297.5139\n",
      "Epoch [175/250], Train Loss: 7292.4185, Val Loss: 2295.8450, Test Loss: 16014.4141\n",
      "Saved best model with validation loss: 2295.8450\n",
      "Epoch [176/250], Train Loss: 7286.4170, Val Loss: 2294.7927, Test Loss: 15989.2402\n",
      "Saved best model with validation loss: 2294.7927\n",
      "Epoch [177/250], Train Loss: 7280.3149, Val Loss: 2293.2532, Test Loss: 15983.1182\n",
      "Saved best model with validation loss: 2293.2532\n",
      "Epoch [178/250], Train Loss: 7274.2900, Val Loss: 2291.1360, Test Loss: 15990.9238\n",
      "Saved best model with validation loss: 2291.1360\n",
      "Epoch [179/250], Train Loss: 7268.2124, Val Loss: 2289.5417, Test Loss: 15982.3242\n",
      "Saved best model with validation loss: 2289.5417\n",
      "Epoch [180/250], Train Loss: 7262.1646, Val Loss: 2288.3279, Test Loss: 15961.4688\n",
      "Saved best model with validation loss: 2288.3279\n",
      "Epoch [181/250], Train Loss: 7256.0786, Val Loss: 2286.8511, Test Loss: 15948.6494\n",
      "Saved best model with validation loss: 2286.8511\n",
      "Epoch [182/250], Train Loss: 7250.0962, Val Loss: 2284.2600, Test Loss: 15956.0986\n",
      "Saved best model with validation loss: 2284.2600\n",
      "Epoch [183/250], Train Loss: 7243.9746, Val Loss: 2282.9983, Test Loss: 15947.1270\n",
      "Saved best model with validation loss: 2282.9983\n",
      "Epoch [184/250], Train Loss: 7238.0913, Val Loss: 2281.7117, Test Loss: 15927.0107\n",
      "Saved best model with validation loss: 2281.7117\n",
      "Epoch [185/250], Train Loss: 7231.8877, Val Loss: 2280.0349, Test Loss: 15922.7852\n",
      "Saved best model with validation loss: 2280.0349\n",
      "Epoch [186/250], Train Loss: 7225.9673, Val Loss: 2277.5801, Test Loss: 15931.1992\n",
      "Saved best model with validation loss: 2277.5801\n",
      "Epoch [187/250], Train Loss: 7219.8184, Val Loss: 2276.5120, Test Loss: 15913.2227\n",
      "Saved best model with validation loss: 2276.5120\n",
      "Epoch [188/250], Train Loss: 7213.8750, Val Loss: 2275.2161, Test Loss: 15899.3008\n",
      "Saved best model with validation loss: 2275.2161\n",
      "Epoch [189/250], Train Loss: 7207.6445, Val Loss: 2273.3521, Test Loss: 15898.5059\n",
      "Saved best model with validation loss: 2273.3521\n",
      "Epoch [190/250], Train Loss: 7201.8149, Val Loss: 2271.1941, Test Loss: 15901.2578\n",
      "Saved best model with validation loss: 2271.1941\n",
      "Epoch [191/250], Train Loss: 7195.5391, Val Loss: 2269.8262, Test Loss: 15882.1055\n",
      "Saved best model with validation loss: 2269.8262\n",
      "Epoch [192/250], Train Loss: 7189.6436, Val Loss: 2269.0156, Test Loss: 15856.7168\n",
      "Saved best model with validation loss: 2269.0156\n",
      "Epoch [193/250], Train Loss: 7183.4365, Val Loss: 2267.0208, Test Loss: 15860.1641\n",
      "Saved best model with validation loss: 2267.0208\n",
      "Epoch [194/250], Train Loss: 7177.3687, Val Loss: 2264.9143, Test Loss: 15863.3398\n",
      "Saved best model with validation loss: 2264.9143\n",
      "Epoch [195/250], Train Loss: 7171.4028, Val Loss: 2263.0813, Test Loss: 15858.7656\n",
      "Saved best model with validation loss: 2263.0813\n",
      "Epoch [196/250], Train Loss: 7165.2246, Val Loss: 2262.4131, Test Loss: 15837.0312\n",
      "Saved best model with validation loss: 2262.4131\n",
      "Epoch [197/250], Train Loss: 7159.2227, Val Loss: 2261.5896, Test Loss: 15827.2295\n",
      "Saved best model with validation loss: 2261.5896\n",
      "Epoch [198/250], Train Loss: 7153.0996, Val Loss: 2259.5850, Test Loss: 15835.6484\n",
      "Saved best model with validation loss: 2259.5850\n",
      "Epoch [199/250], Train Loss: 7147.0947, Val Loss: 2257.6931, Test Loss: 15840.6621\n",
      "Saved best model with validation loss: 2257.6931\n",
      "Epoch [200/250], Train Loss: 7140.9595, Val Loss: 2256.3987, Test Loss: 15821.2734\n",
      "Saved best model with validation loss: 2256.3987\n",
      "Epoch [201/250], Train Loss: 7134.9224, Val Loss: 2256.1133, Test Loss: 15789.0918\n",
      "Saved best model with validation loss: 2256.1133\n",
      "Epoch [202/250], Train Loss: 7128.8774, Val Loss: 2253.5649, Test Loss: 15799.7832\n",
      "Saved best model with validation loss: 2253.5649\n",
      "Epoch [203/250], Train Loss: 7122.6978, Val Loss: 2251.1367, Test Loss: 15807.9482\n",
      "Saved best model with validation loss: 2251.1367\n",
      "Epoch [204/250], Train Loss: 7116.7036, Val Loss: 2250.3862, Test Loss: 15782.8867\n",
      "Saved best model with validation loss: 2250.3862\n",
      "Epoch [205/250], Train Loss: 7110.5161, Val Loss: 2249.9199, Test Loss: 15760.8594\n",
      "Saved best model with validation loss: 2249.9199\n",
      "Epoch [206/250], Train Loss: 7104.4233, Val Loss: 2248.3235, Test Loss: 15765.6543\n",
      "Saved best model with validation loss: 2248.3235\n",
      "Epoch [207/250], Train Loss: 7098.3340, Val Loss: 2246.1953, Test Loss: 15767.9844\n",
      "Saved best model with validation loss: 2246.1953\n",
      "Epoch [208/250], Train Loss: 7092.1919, Val Loss: 2244.7993, Test Loss: 15752.3379\n",
      "Saved best model with validation loss: 2244.7993\n",
      "Epoch [209/250], Train Loss: 7086.1196, Val Loss: 2244.4465, Test Loss: 15725.4961\n",
      "Saved best model with validation loss: 2244.4465\n",
      "Epoch [210/250], Train Loss: 7079.9897, Val Loss: 2243.4407, Test Loss: 15715.6055\n",
      "Saved best model with validation loss: 2243.4407\n",
      "Epoch [211/250], Train Loss: 7073.9009, Val Loss: 2240.1160, Test Loss: 15721.9668\n",
      "Saved best model with validation loss: 2240.1160\n",
      "Epoch [212/250], Train Loss: 7067.7368, Val Loss: 2238.1477, Test Loss: 15715.6406\n",
      "Saved best model with validation loss: 2238.1477\n",
      "Epoch [213/250], Train Loss: 7061.6250, Val Loss: 2237.3181, Test Loss: 15700.3398\n",
      "Saved best model with validation loss: 2237.3181\n",
      "Epoch [214/250], Train Loss: 7055.4492, Val Loss: 2236.6028, Test Loss: 15683.1309\n",
      "Saved best model with validation loss: 2236.6028\n",
      "Epoch [215/250], Train Loss: 7049.3540, Val Loss: 2233.8225, Test Loss: 15692.9316\n",
      "Saved best model with validation loss: 2233.8225\n",
      "Epoch [216/250], Train Loss: 7043.1411, Val Loss: 2232.7356, Test Loss: 15680.4785\n",
      "Saved best model with validation loss: 2232.7356\n",
      "Epoch [217/250], Train Loss: 7037.0083, Val Loss: 2230.8608, Test Loss: 15667.0908\n",
      "Saved best model with validation loss: 2230.8608\n",
      "Epoch [218/250], Train Loss: 7030.8750, Val Loss: 2229.9553, Test Loss: 15659.1992\n",
      "Saved best model with validation loss: 2229.9553\n",
      "Epoch [219/250], Train Loss: 7024.7012, Val Loss: 2227.0879, Test Loss: 15674.3750\n",
      "Saved best model with validation loss: 2227.0879\n",
      "Epoch [220/250], Train Loss: 7018.5205, Val Loss: 2226.4248, Test Loss: 15651.1816\n",
      "Saved best model with validation loss: 2226.4248\n",
      "Epoch [221/250], Train Loss: 7012.3115, Val Loss: 2225.4768, Test Loss: 15632.8984\n",
      "Saved best model with validation loss: 2225.4768\n",
      "Epoch [222/250], Train Loss: 7006.1221, Val Loss: 2223.0525, Test Loss: 15631.9297\n",
      "Saved best model with validation loss: 2223.0525\n",
      "Epoch [223/250], Train Loss: 6999.8784, Val Loss: 2219.9119, Test Loss: 15645.3477\n",
      "Saved best model with validation loss: 2219.9119\n",
      "Epoch [224/250], Train Loss: 6993.6704, Val Loss: 2219.3013, Test Loss: 15630.3730\n",
      "Saved best model with validation loss: 2219.3013\n",
      "Epoch [225/250], Train Loss: 6987.4512, Val Loss: 2220.2488, Test Loss: 15595.7695\n",
      "Epoch [226/250], Train Loss: 6981.2354, Val Loss: 2217.8286, Test Loss: 15595.8848\n",
      "Saved best model with validation loss: 2217.8286\n",
      "Epoch [227/250], Train Loss: 6975.0576, Val Loss: 2214.6909, Test Loss: 15611.8340\n",
      "Saved best model with validation loss: 2214.6909\n",
      "Epoch [228/250], Train Loss: 6968.7925, Val Loss: 2213.8591, Test Loss: 15594.3496\n",
      "Saved best model with validation loss: 2213.8591\n",
      "Epoch [229/250], Train Loss: 6962.6143, Val Loss: 2213.9751, Test Loss: 15560.6504\n",
      "Epoch [230/250], Train Loss: 6956.3584, Val Loss: 2213.0327, Test Loss: 15552.3652\n",
      "Saved best model with validation loss: 2213.0327\n",
      "Epoch [231/250], Train Loss: 6950.2012, Val Loss: 2210.3625, Test Loss: 15576.7812\n",
      "Saved best model with validation loss: 2210.3625\n",
      "Epoch [232/250], Train Loss: 6943.9072, Val Loss: 2208.5608, Test Loss: 15573.0283\n",
      "Saved best model with validation loss: 2208.5608\n",
      "Epoch [233/250], Train Loss: 6937.7554, Val Loss: 2208.7585, Test Loss: 15534.1016\n",
      "Epoch [234/250], Train Loss: 6931.4580, Val Loss: 2207.8474, Test Loss: 15516.6016\n",
      "Saved best model with validation loss: 2207.8474\n",
      "Epoch [235/250], Train Loss: 6925.3188, Val Loss: 2203.9424, Test Loss: 15536.6748\n",
      "Saved best model with validation loss: 2203.9424\n",
      "Epoch [236/250], Train Loss: 6919.0244, Val Loss: 2202.9341, Test Loss: 15529.5215\n",
      "Saved best model with validation loss: 2202.9341\n",
      "Epoch [237/250], Train Loss: 6912.8467, Val Loss: 2203.5474, Test Loss: 15489.5508\n",
      "Epoch [238/250], Train Loss: 6906.5718, Val Loss: 2201.1809, Test Loss: 15479.7812\n",
      "Saved best model with validation loss: 2201.1809\n",
      "Epoch [239/250], Train Loss: 6900.4424, Val Loss: 2197.2839, Test Loss: 15499.8730\n",
      "Saved best model with validation loss: 2197.2839\n",
      "Epoch [240/250], Train Loss: 6894.1309, Val Loss: 2196.4973, Test Loss: 15485.4072\n",
      "Saved best model with validation loss: 2196.4973\n",
      "Epoch [241/250], Train Loss: 6888.0200, Val Loss: 2196.6162, Test Loss: 15448.4092\n",
      "Epoch [242/250], Train Loss: 6881.6987, Val Loss: 2195.3887, Test Loss: 15428.2451\n",
      "Saved best model with validation loss: 2195.3887\n",
      "Epoch [243/250], Train Loss: 6875.6025, Val Loss: 2191.8738, Test Loss: 15445.5645\n",
      "Saved best model with validation loss: 2191.8738\n",
      "Epoch [244/250], Train Loss: 6869.2871, Val Loss: 2190.9207, Test Loss: 15444.7109\n",
      "Saved best model with validation loss: 2190.9207\n",
      "Epoch [245/250], Train Loss: 6863.2090, Val Loss: 2191.0198, Test Loss: 15406.7686\n",
      "Epoch [246/250], Train Loss: 6856.8999, Val Loss: 2190.3772, Test Loss: 15389.4414\n",
      "Saved best model with validation loss: 2190.3772\n",
      "Epoch [247/250], Train Loss: 6850.7104, Val Loss: 2187.2700, Test Loss: 15403.3359\n",
      "Saved best model with validation loss: 2187.2700\n",
      "Epoch [248/250], Train Loss: 6844.4468, Val Loss: 2185.6313, Test Loss: 15406.2148\n",
      "Saved best model with validation loss: 2185.6313\n",
      "Epoch [249/250], Train Loss: 6838.3105, Val Loss: 2185.0786, Test Loss: 15376.2305\n",
      "Saved best model with validation loss: 2185.0786\n",
      "Epoch [250/250], Train Loss: 6832.0444, Val Loss: 2184.3274, Test Loss: 15344.7217\n",
      "Saved best model with validation loss: 2184.3274\n",
      "Training finished!\n",
      "Saved last model\n",
      "Final Test Loss: 15344.7217\n"
     ]
    }
   ],
   "source": [
    "device = config['cuda_device']\n",
    "num_epochs = config['epoch']\n",
    "\n",
    "\n",
    "model = ResidualAttentionModel_92_32input_update()\n",
    "model.to(device)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "os.makedirs('./log', exist_ok=True)\n",
    "os.makedirs('./weights', exist_ok=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(dataset, batch_size=config['batch_size'])\n",
    "\n",
    "with open(f\"./log/{config['current_time']}_{config['model_type']}_{config['epoch']}.txt\", \"a\") as log_file:\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (x, _, z) in enumerate(train_loader):\n",
    "            x, z = x.to(device), z.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, z)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, _, z in val_loader:\n",
    "                x, z = x.to(device), z.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, z)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Test\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, _, z in test_loader:\n",
    "                x, z = x.to(device), z.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, z)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "        \n",
    "        # Log the losses of each epoch to the file\n",
    "        log_file.write(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Test Loss: {avg_test_loss:.4f}\\n')\n",
    "        log_file.flush() \n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_name = f\"./weights/{config['current_time']}_{config['model_type']}_best.pth\"\n",
    "            torch.save(model.state_dict(), best_model_name)\n",
    "            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# Save the last model\n",
    "last_model_name = f\"./weights/{config['current_time']}_{config['model_type']}_last.pth\"\n",
    "torch.save(model.state_dict(), last_model_name)\n",
    "print(f\"Saved last model\")\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_test_loss = 0\n",
    "    for x, _, z in test_loader:\n",
    "        x, z = x.to(device), z.to(device)\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, z)\n",
    "        final_test_loss += loss.item()\n",
    "    \n",
    "    avg_final_test_loss = final_test_loss / len(test_loader)\n",
    "    print(f\"Final Test Loss: {avg_final_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musong_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
